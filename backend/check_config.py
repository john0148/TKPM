#!/usr/bin/env python3
"""
Script ki·ªÉm tra nhanh c·∫•u h√¨nh GPU v√† models
"""

import torch
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def check_gpu_config():
    """Ki·ªÉm tra c·∫•u h√¨nh GPU"""
    logger.info("=== GPU Configuration Check ===")
    
    if not torch.cuda.is_available():
        logger.error("‚ùå CUDA kh√¥ng kh·∫£ d·ª•ng!")
        return False
    
    device_count = torch.cuda.device_count()
    logger.info(f"‚úÖ CUDA available, {device_count} device(s) found")
    
    for i in range(device_count):
        device_name = torch.cuda.get_device_name(i)
        memory_gb = torch.cuda.get_device_properties(i).total_memory / 1024**3
        logger.info(f"  GPU {i}: {device_name} ({memory_gb:.1f} GB)")
    
    if device_count >= 2:
        logger.info("‚úÖ ƒê·ªß GPU cho c·∫•u h√¨nh t·ªëi ∆∞u:")
        logger.info("  - DreamO: cuda:0")
        logger.info("  - OmniGen2: cuda:1")
    else:
        logger.warning("‚ö†Ô∏è Ch·ªâ c√≥ 1 GPU, c·∫£ hai models s·∫Ω ch·∫°y tr√™n cuda:0")
    
    return True

def check_model_paths():
    """Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n models"""
    logger.info("=== Model Paths Check ===")
    
    import os
    
    paths_to_check = [
        ("../DreamO", "DreamO"),
        ("../OmniGen2-DFloat11", "OmniGen2"),
        ("models", "Backend models"),
        ("routes", "API routes"),
        ("schemas", "Schemas")
    ]
    
    all_good = True
    for path, name in paths_to_check:
        if os.path.exists(path):
            logger.info(f"‚úÖ {name}: {path}")
        else:
            logger.error(f"‚ùå {name}: {path} not found")
            all_good = False
    
    return all_good

def check_dependencies():
    """Ki·ªÉm tra dependencies"""
    logger.info("=== Dependencies Check ===")
    
    required_packages = [
        "torch",
        "transformers", 
        "diffusers",
        "accelerate",
        "fastapi",
        "uvicorn",
        "pillow",
        "numpy"
    ]
    
    all_good = True
    for package in required_packages:
        try:
            __import__(package)
            logger.info(f"‚úÖ {package}")
        except ImportError:
            logger.error(f"‚ùå {package} not installed")
            all_good = False
    
    return all_good

def main():
    """Main check function"""
    logger.info("üîç Quick Configuration Check")
    
    # Check GPU
    gpu_ok = check_gpu_config()
    
    # Check paths
    paths_ok = check_model_paths()
    
    # Check dependencies
    deps_ok = check_dependencies()
    
    # Summary
    logger.info("=== Summary ===")
    if gpu_ok and paths_ok and deps_ok:
        logger.info("üéâ T·∫•t c·∫£ ki·ªÉm tra ƒë·ªÅu pass! C√≥ th·ªÉ ch·∫°y backend.")
        logger.info("üí° Ch·∫°y: python start_backend.py")
    else:
        logger.error("‚ùå C√≥ v·∫•n ƒë·ªÅ v·ªõi c·∫•u h√¨nh. Vui l√≤ng ki·ªÉm tra l·∫°i.")
        
        if not gpu_ok:
            logger.error("  - GPU/CUDA kh√¥ng kh·∫£ d·ª•ng")
        if not paths_ok:
            logger.error("  - Thi·∫øu ƒë∆∞·ªùng d·∫´n models")
        if not deps_ok:
            logger.error("  - Thi·∫øu dependencies")

if __name__ == "__main__":
    main() 